{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad595e1",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models (DDPM)\n",
    "\n",
    "Neste notebook, exploraremos a implementação de um modelo de difusão (DDPM) utilizando PyTorch. Para facilitar a compreensão dos conceitos fundamentais sem a complexidade computacional de imagens de alta resolução, aplicaremos o modelo a um dataset bidimensional.\n",
    "\n",
    "O objetivo é aprender a distribuição $p(x)$ dos dados de forma que possamos gerar novos pontos que pertençam a essa mesma geometria, partindo de ruído aleatório. O processo se divide em:\n",
    "1.  **Processo Forward (Difusão):** Adição progressiva de ruído gaussiano aos dados até que a distribuição se torne uma normal isotrópica $\\mathcal{N}(0, I)$.\n",
    "2.  **Processo Reverse (Desruído):** Treinamento de uma rede neural para estimar e remover o ruído em cada passo temporal, recuperando a estrutura original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device definido como: {device}\")\n",
    "\n",
    "# Semente para reprodutibilidade\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94446181",
   "metadata": {},
   "source": [
    "## Preparação dos Dados\n",
    "\n",
    "Utilizaremos uma distribuição de pontos 2D como nosso conjunto de dados $x_0$. A natureza não linear dessa distribuição é um bom teste para a capacidade generativa do modelo. Geraremos os dados sinteticamente, normalizando-os para o intervalo padrão, o que estabiliza o treinamento da rede neural.\n",
    "\n",
    "Visualizaremos os dados originais para ter uma referência (\"Ground Truth\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dino_dataset(n=8000):\n",
    "    df = pd.read_csv(\"data/dino.tsv\", sep=\"\\t\")\n",
    "    df = df[df[\"dataset\"] == \"dino\"]\n",
    "\n",
    "    rng = np.random.default_rng(42)\n",
    "    ix = rng.integers(0, len(df), n)\n",
    "    x = df[\"x\"].iloc[ix].tolist()\n",
    "    x = np.array(x) + rng.normal(size=len(x)) * 0.15\n",
    "    y = df[\"y\"].iloc[ix].tolist()\n",
    "    y = np.array(y) + rng.normal(size=len(x)) * 0.15\n",
    "    x = (x/54 - 1) * 4\n",
    "    y = (y/48 - 1) * 4\n",
    "    X = np.stack((x, y), axis=1)\n",
    "    return torch.from_numpy(X.astype(np.float32))\n",
    "\n",
    "n_samples = 2000\n",
    "batch_size = 128\n",
    "\n",
    "X_train = dino_dataset(n_samples)\n",
    "dataset = TensorDataset(X_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], s=5, alpha=0.6, label='Dados Reais')\n",
    "plt.title(\"Distribuição (x_0)\")\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2cfdd",
   "metadata": {},
   "source": [
    "## O Processo de Difusão (Forward Process)\n",
    "\n",
    "O processo de difusão é definido por uma cadeia de Markov que adiciona ruído aos dados em $T$ passos. A quantidade de ruído adicionada em cada passo é controlada por um *schedule* de variância $\\beta_t$.\n",
    "\n",
    "Podemos amostrar $x_t$ em qualquer passo temporal arbitrário $t$ diretamente de $x_0$ usando a propriedade de reparametrização gaussiana:\n",
    "\n",
    "$$\n",
    "q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1 - \\bar{\\alpha}_t) \\mathbf{I})\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "* $\\alpha_t = 1 - \\beta_t$\n",
    "* $\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s$\n",
    "\n",
    "Neste exemplo, usaremos $T=100$ passos, o que é suficiente para este problema simples (em imagens complexas, $T$ costuma ser 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros de Difusão\n",
    "n_steps = 100\n",
    "beta_start = 1e-4 # 0.0001\n",
    "beta_end = 0.02\n",
    "\n",
    "# Definindo o schedule linear de beta\n",
    "betas = torch.linspace(beta_start, beta_end, n_steps).to(device)\n",
    "\n",
    "# Calculando alphas e alphas acumulados\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "# Cálculos auxiliares para a amostragem q(x_t | x_0)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
    "\n",
    "def q_sample(x_0, t, noise=None):\n",
    "    \"\"\"\n",
    "    Amostra x_t a partir de x_0 dado um passo t.\n",
    "    Forward process: x_t = sqrt(alpha_bar) * x_0 + sqrt(1 - alpha_bar) * epsilon\n",
    "    \"\"\"\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_0)\n",
    "        \n",
    "    sqrt_alpha_t = sqrt_alphas_cumprod[t].reshape(-1, 1)\n",
    "    sqrt_one_minus_alpha_t = sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1)\n",
    "    \n",
    "    return sqrt_alpha_t * x_0 + sqrt_one_minus_alpha_t * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27931e",
   "metadata": {},
   "source": [
    "## Arquitetura do Modelo (Reverse Process)\n",
    "\n",
    "O objetivo da rede neural é prever o ruído $\\epsilon$ adicionado a uma imagem ruidosa $x_t$, dado o passo de tempo $t$. Ou seja, a rede aprende $\\epsilon_\\theta(x_t, t)$.\n",
    "\n",
    "Para este problema 2D, não precisamos de uma U-Net complexa com convoluções. Utilizaremos um **MLP (Multi-Layer Perceptron) condicional**. A arquitetura consiste em:\n",
    "\n",
    "1.  **Entrada:** Coordenadas 2D $(x, y)$.\n",
    "2.  **Time Embedding:** O passo de tempo $t$ é codificado usando *Sinusoidal Positional Embeddings* (similar aos Transformers) para que a rede tenha noção da \"intensidade\" do ruído naquele momento.\n",
    "3.  **Blocos Residuais/Lineares:** Camadas densas com ativação GELU. O embedding de tempo é concatenado ou somado às features intermediárias.\n",
    "\n",
    "A função de perda (Loss) é o erro quadrático médio (MSE) entre o ruído real adicionado e o ruído previsto pela rede:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = || \\epsilon - \\epsilon_\\theta(x_t, t) ||^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb7b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = np.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c745791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), # Mantendo a dimensionalidade\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimpleDiffusionMLP(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=128, time_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Codificação do tempo\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_dim),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # O modelo processa a concatenação do input e do tempo\n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_dim + time_dim, hidden_dim)\n",
    "        \n",
    "        # Hidden layers (espécie de ResNet simples para dados tabulares)\n",
    "        self.block1 = Block(hidden_dim, hidden_dim)\n",
    "        self.block2 = Block(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Output layer (predição do ruído, mesma dimensão da entrada)\n",
    "        self.output_layer = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # 1. Obter embedding do tempo\n",
    "        t_emb = self.time_mlp(t)\n",
    "        \n",
    "        # 2. Concatenar x com t_emb\n",
    "        # x: [batch, 2], t_emb: [batch, time_dim] -> x_input: [batch, 2+time_dim]\n",
    "        x_input = torch.cat([x, t_emb], dim=1)\n",
    "        \n",
    "        # 3. Passar pela rede\n",
    "        h = self.input_layer(x_input)\n",
    "        h = h + self.block1(h) # Conexão residual simples\n",
    "        h = h + self.block2(h)\n",
    "        \n",
    "        return self.output_layer(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9636880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o modelo\n",
    "model = SimpleDiffusionMLP().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456eac93",
   "metadata": {},
   "source": [
    "## Loop de Treinamento\n",
    "\n",
    "O algoritmo de treinamento segue os passos padrão do DDPM:\n",
    "1.  Amostramos um batch de dados reais $x_0$.\n",
    "2.  Amostramos aleatoriamente passos de tempo $t$ para cada ponto do batch (distribuição uniforme entre $0$ e $T-1$).\n",
    "3.  Geramos ruído gaussiano $\\epsilon \\sim \\mathcal{N}(0, I)$.\n",
    "4.  Criamos a versão ruidosa $x_t$ usando a função `q_sample`.\n",
    "5.  O modelo tenta prever $\\epsilon$ a partir de $x_t$ e $t$.\n",
    "6.  Calculamos o gradiente descendente no erro MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (x0_batch,) in enumerate(dataloader):\n",
    "        x0_batch = x0_batch.to(device)\n",
    "        batch_size_current = x0_batch.shape[0]\n",
    "        \n",
    "        # 1. Amostrar t uniformemente\n",
    "        t = torch.randint(0, n_steps, (batch_size_current,), device=device).long()\n",
    "        \n",
    "        # 2. Gerar ruído aleatório\n",
    "        noise = torch.randn_like(x0_batch)\n",
    "        \n",
    "        # 3. Gerar x_t (imagem ruidosa)\n",
    "        x_t = q_sample(x0_batch, t, noise)\n",
    "        \n",
    "        # 4. Predição do modelo\n",
    "        predicted_noise = model(x_t, t)\n",
    "        \n",
    "        # 5. Cálculo da Loss\n",
    "        loss = nn.MSELoss()(predicted_noise, noise)\n",
    "        \n",
    "        # 6. Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} | Loss: {avg_loss:.5f}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title(\"Curva de Aprendizado (Loss)\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a998971",
   "metadata": {},
   "source": [
    "## Amostragem (Reverse Process)\n",
    "\n",
    "Para gerar novos dados, começamos com ruído puro $x_T \\sim \\mathcal{N}(0, I)$ e iteramos para trás, de $T$ até $0$. A equação de atualização para remover o ruído é:\n",
    "\n",
    "$$\n",
    "x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z\n",
    "$$\n",
    "\n",
    "Onde $z \\sim \\mathcal{N}(0, I)$ é um ruído auxiliar que adicionamos em todos os passos (exceto no último, $t=0$) para manter a estocasticidade do processo generativo. Se não adicionarmos $z$, o processo se torna determinístico (similar ao DDIM).\n",
    "\n",
    "Vamos gerar novos pontos e verificar se eles formam a geometria original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc905a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def p_sample_loop(model, shape):\n",
    "    device = next(model.parameters()).device\n",
    "    x = torch.randn(shape, device=device)\n",
    "\n",
    "    for t in reversed(range(n_steps)):\n",
    "        ts = torch.full((shape[0],), t, device=device, dtype=torch.long)\n",
    "        eps = model(x, ts)\n",
    "\n",
    "        a = alphas[t]\n",
    "        b = betas[t]\n",
    "        sqrt_oma = sqrt_one_minus_alphas_cumprod[t]\n",
    "\n",
    "        mean = (x - b * eps / sqrt_oma) / torch.sqrt(a)\n",
    "        x = mean if t == 0 else mean + torch.sqrt(b) * torch.randn_like(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13197da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "data = p_sample_loop(model, (1000, 2)).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c='gray', alpha=0.1)\n",
    "plt.scatter(data[:,0], data[:,1], c='blue', s=10)\n",
    "plt.axis('equal')\n",
    "plt.title(\"DDPM: Dados Gerados\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbdb741",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def p_sample_trajectory(model, shape):\n",
    "    device = next(model.parameters()).device\n",
    "    x = torch.randn(shape, device=device)\n",
    "    traj = [x.cpu().numpy()]\n",
    "\n",
    "    for t in reversed(range(n_steps)):\n",
    "        ts = torch.full((shape[0],), t, device=device, dtype=torch.long)\n",
    "        eps = model(x, ts)\n",
    "\n",
    "        a = alphas[t]\n",
    "        b = betas[t]\n",
    "        sqrt_oma = sqrt_one_minus_alphas_cumprod[t]\n",
    "\n",
    "        mean = (x - b * eps / sqrt_oma) / torch.sqrt(a)\n",
    "        x = mean if t == 0 else mean + torch.sqrt(b) * torch.randn_like(x)\n",
    "\n",
    "        traj.append(x.cpu().numpy())\n",
    "\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ffc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.linspace(0, n_steps, 6, dtype=int)\n",
    "traj = p_sample_trajectory(model, (1000, 2))\n",
    "\n",
    "fig, axs = plt.subplots(1, len(steps), figsize=(18,3))\n",
    "\n",
    "for ax, s in zip(axs, steps):\n",
    "    s = min(s, len(traj)-1)\n",
    "    ax.scatter(traj[s][:,0], traj[s][:,1], s=2, c='blue')\n",
    "    ax.set_title(f\"t={s}\")\n",
    "    ax.set_xlim(-5.2,5.2)\n",
    "    ax.set_ylim(-5.2,5.2)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "\n",
    "def save_ddpm_video(traj, filename=\"ddpm_video.mp4\", fps=20):\n",
    "    frames = []\n",
    "\n",
    "    for data in traj:\n",
    "        fig, ax = plt.subplots(figsize=(4,4))\n",
    "        ax.scatter(data[:,0], data[:,1], s=2)\n",
    "        ax.set_xlim(-4, 4)\n",
    "        ax.set_ylim(-4, 4)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        rgba = np.asarray(fig.canvas.buffer_rgba())\n",
    "        rgb = rgba[..., :3]\n",
    "        frames.append(rgb)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.close(fig)\n",
    "\n",
    "    imageio.mimsave(filename, frames, fps=fps)\n",
    "    print(\"Vídeo salvo em:\", filename)\n",
    "\n",
    "traj = p_sample_trajectory(model, (1000, 2))\n",
    "save_ddpm_video(traj, \"data/ddpm_dino.mp4\", fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
