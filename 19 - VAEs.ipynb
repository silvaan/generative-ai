{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b691206f",
   "metadata": {},
   "source": [
    "# Variational Autoencoders (VAEs)\n",
    "\n",
    "Os Variational Autoencoders (VAEs) representam uma classe fundamental de modelos generativos profundos que combinam inferência bayesiana aproximada com redes neurais. Diferentemente dos Autoencoders (AEs) tradicionais, que mapeiam a entrada para um vetor latente fixo, os VAEs mapeiam a entrada para uma distribuição de probabilidade no espaço latente. Isso impõe uma estrutura contínua e regularizada ao espaço latente, permitindo não apenas a reconstrução eficaz dos dados, mas também a geração de novas amostras através da amostragem dessa distribuição aprendida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a476ca2",
   "metadata": {},
   "source": [
    "## Formulação\n",
    "\n",
    "O objetivo central em um modelo generativo é aprender a distribuição verdadeira dos dados $p_{data}(x)$ ou aproximá-la através de um modelo parametrizado $p_\\theta(x)$. Em modelos de variáveis latentes, assumimos que os dados observáveis $x$ são gerados por um processo oculto envolvendo variáveis latentes $z$. A probabilidade marginal dos dados é dada pela integral:\n",
    "\n",
    "$$p_\\theta(x) = \\int p_\\theta(x|z) p(z) dz$$\n",
    "\n",
    "Onde:\n",
    "* $p(z)$ é a distribuição a priori (prior) das variáveis latentes, geralmente assumida como uma Gaussiana normal padrão $\\mathcal{N}(0, I)$.\n",
    "* $p_\\theta(x|z)$ é a distribuição de verossimilhança (likelihood), modelada pelo decodificador (rede neural).\n",
    "\n",
    "O cálculo direto desta integral é intratável para redes neurais profundas, pois requer a integração sobre todas as configurações possíveis de $z$. Da mesma forma, a distribuição posterior verdadeira $p_\\theta(z|x) = p_\\theta(x|z)p(z) / p_\\theta(x)$ é intratável devido ao denominador.\n",
    "\n",
    "## Inferência Variacional e ELBO\n",
    "\n",
    "Para contornar a intratabilidade, introduzimos uma distribuição variacional $q_\\phi(z|x)$ (o codificador) para aproximar a posterior verdadeira $p_\\theta(z|x)$. Nosso objetivo é minimizar a Divergência de Kullback-Leibler (KL) entre a aproximação e a posterior verdadeira.\n",
    "\n",
    "Entretanto, como não conhecemos a posterior verdadeira, maximizamos o limite inferior variacional, conhecido como **Evidence Lower Bound (ELBO)**:\n",
    "\n",
    "$$\\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)] - D_{KL}(q_\\phi(z|x) || p(z))$$\n",
    "\n",
    "Esta função objetivo possui dois componentes cruciais:\n",
    "1.  **Erro de Reconstrução**: $\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]$, que incentiva o decodificador a reconstruir os dados $x$ eficientemente a partir das amostras latentes.\n",
    "2.  **Termo de Regularização**: $D_{KL}(q_\\phi(z|x) || p(z))$, que força a distribuição latente aprendida a se aproximar da prior $p(z)$ (geralmente Gaussiana), garantindo continuidade e completude no espaço latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local hyperparameters for data loading\n",
    "batch_size = 128\n",
    "\n",
    "# Data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset setup\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b2e6b",
   "metadata": {},
   "source": [
    "## Arquitetura e o Truque de Reparametrização\n",
    "\n",
    "A implementação do VAE exige um mecanismo diferenciável para amostrar $z$. O **Truque de Reparametrização** permite isso ao expressar a variável aleatória $z$ como uma transformação determinística de uma variável de ruído $\\epsilon$:\n",
    "\n",
    "$$z = \\mu + \\sigma \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)$$\n",
    "\n",
    "Dessa forma, o gradiente pode fluir através de $\\mu$ e $\\sigma$ durante a retropropagação, enquanto a estocasticidade permanece isolada em $\\epsilon$. A rede codificadora projeta a entrada em dois vetores: $\\mu$ (média) e $\\log(\\sigma^2)$ (log-variância). O uso do logaritmo garante estabilidade numérica e evita restrições de não-negatividade na saída da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb6ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc_mu(h1), self.fc_logvar(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b26ba66",
   "metadata": {},
   "source": [
    "## Função de Custo\n",
    "\n",
    "A perda total é a soma do erro de reconstrução (Binary Cross Entropy) e da Divergência KL analítica para gaussianas.\n",
    "\n",
    "$$D_{KL} = -\\frac{1}{2} \\sum_{j=1}^{J} (1 + \\log(\\sigma_j^2) - \\mu_j^2 - \\sigma_j^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad94ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # Reconstruction term\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # KL Divergence term\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "model = VAE(latent_dim=latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a54ae",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Instanciamos o modelo e o otimizador localmente. Definimos uma dimensão latente de 2 (`latent_dim = 2`) especificamente para facilitar a visualização posterior do plano 2D, embora em aplicações reais de compressão dimensões maiores sejam preferíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch: {epoch} \\tAverage Loss: {train_loss / len(train_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c791c6",
   "metadata": {},
   "source": [
    "## Análise de Reconstrução\n",
    "\n",
    "O VAE deve ser capaz de mapear uma entrada $x$ para uma distribuição latente e, a partir de uma amostra $z$, recuperar uma aproximação $\\hat{x}$ que preserve a semântica original.\n",
    "\n",
    "Diferentemente de um Autoencoder determinístico, esperamos que as reconstruções do VAE sejam ligeiramente \"enevoadas\" (blurry). Isso ocorre devido à natureza probabilística do modelo e ao termo de regularização KL na função de perda, que força o espaço latente a ser suave e contínuo, sacrificando parte da fidelidade de alta frequência em prol de uma melhor capacidade de generalização e geração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 8\n",
    "model.eval()\n",
    "data, _ = next(iter(test_loader))\n",
    "data = data.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    recon_batch, _, _ = model(data)\n",
    "\n",
    "data = data.cpu()\n",
    "recon_batch = recon_batch.cpu()\n",
    "\n",
    "fig, axes = plt.subplots(2, num_imgs, figsize=(12, 4))\n",
    "\n",
    "for i in range(num_imgs):\n",
    "    # Original images\n",
    "    axes[0, i].imshow(data[i].reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Reconstructed images\n",
    "    axes[1, i].imshow(recon_batch[i].reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_title(\"Original Input\", fontsize=12, loc='left')\n",
    "axes[1, 0].set_title(\"VAE Reconstruction\", fontsize=12, loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54a4a9",
   "metadata": {},
   "source": [
    "## Geração Estocástica de Amostras\n",
    "\n",
    "Uma vez treinado, o decodificador do VAE atua como um gerador determinístico $p_\\theta(x|z)$. Para criar novas amostras que não existem no dataset original, realizamos a amostragem de vetores latentes a partir da distribuição a priori $p(z) = \\mathcal{N}(0, I)$.\n",
    "\n",
    "Como o treinamento forçou a distribuição latente dos dados a se aproximar dessa normal padrão (via termo KL), temos alta confiança de que pontos amostrados aleatoriamente dessa região resultarão em imagens semanticamente válidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd293f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 8\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(num_samples, latent_dim).to(device)\n",
    "    samples = model.decode(z).cpu()\n",
    "    \n",
    "plt.figure(figsize=(14, 4))\n",
    "for i in range(num_samples):\n",
    "    ax = plt.subplot(2, 8, i + 1)\n",
    "    plt.imshow(samples[i].view(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Generated Samples from N(0, I)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b9571",
   "metadata": {},
   "source": [
    "## Visualização do Manifold Latente\n",
    "\n",
    "Como restringimos `latent_dim = 2`, podemos mapear diretamente o espaço latente 2D para o espaço de imagens. Ao invés de amostragem aleatória, criamos um *grid* de coordenadas linearmente espaçadas (usando a função de distribuição acumulada inversa para cobrir as regiões de maior densidade de probabilidade).\n",
    "\n",
    "Isso nos permite visualizar a suavidade do espaço latente, observando como o modelo realiza a \"metamorfose\" contínua entre diferentes classes de dígitos ao percorrer os eixos $z_1$ e $z_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "digit_size = 28\n",
    "model.eval()\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "grid_x = np.linspace(-1.5, 1.5, n)\n",
    "grid_y = np.linspace(-1.5, 1.5, n)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = torch.tensor([[xi, yi]]).float().to(device)\n",
    "            x_decoded = model.decode(z_sample)\n",
    "            digit = x_decoded.view(digit_size, digit_size).cpu().numpy()\n",
    "            \n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                    j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.title(\"Latent Space Manifold (2D)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
