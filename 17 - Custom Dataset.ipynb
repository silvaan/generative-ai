{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac0174d",
   "metadata": {},
   "source": [
    "# Atividade: GANs\n",
    "\n",
    "Neste notebook, você irá **preparar seu próprio dataset** e **treinar uma DCGAN utilizando a distância de Wasserstein**.\n",
    "O objetivo é gerar imagens sintéticas a partir de ruído, aprendendo a distribuição dos dados reais.\n",
    "\n",
    "O treinamento será realizado com um **Gerador** e um **Crítico** (substituindo o discriminador tradicional), aplicando **gradient clipping** para garantir a restrição de Lipschitz exigida pela métrica de Wasserstein.\n",
    "\n",
    "Ao final, o modelo deverá ser capaz de **produzir imagens realistas** a partir de vetores aleatórios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedad1c3",
   "metadata": {},
   "source": [
    "## Preparando os dados\n",
    "\n",
    "Para esta atividade, será necessário baixar ou montar um dataset de imagens de um domínio específico (por exemplo, rostos, paisagens, objetos, etc.). Você pode utilizar datasets públicos como LFW e CelebA ou criar o seu próprio conjunto de imagens armazenadas em uma pasta local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71316a9",
   "metadata": {},
   "source": [
    "### Coleta de Imagens\n",
    "\n",
    "Caso opte por montar seu próprio dataset, você pode utilizar a biblioteca iCrawler para baixar imagens automaticamente a partir de buscadores (como Google, Bing ou Baidu), fornecendo uma lista de termos relacionados ao domínio desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22940326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from icrawler.builtin import GoogleImageCrawler, BingImageCrawler\n",
    "\n",
    "def download_images(keyword, folder, n_total=100):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    downloaded = len(os.listdir(folder))\n",
    "    remaining = n_total - downloaded\n",
    "\n",
    "    while downloaded < n_total:\n",
    "        crawler = GoogleImageCrawler(storage={'root_dir': folder})\n",
    "        crawler.crawl(keyword=keyword, max_num=remaining, file_idx_offset=downloaded)\n",
    "        downloaded = len(os.listdir(folder))\n",
    "        remaining = n_total - downloaded\n",
    "        print(f\"Downloaded {downloaded}/{n_total}\")\n",
    "\n",
    "    print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_images(\"darth vader\", f\"data/vader\", n_total=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039fee3",
   "metadata": {},
   "source": [
    "### Implementação do Dataset\n",
    "\n",
    "Com as imagens já disponíveis, implemente uma **classe de Dataset personalizada** para o PyTorch. Ela deve herdar de `Dataset` e retornar, em cada amostra, a imagem processada pelos **transforms** definidos anteriormente.\n",
    "\n",
    "O Dataset deve:\n",
    "\n",
    "* Ler as imagens a partir de uma pasta.\n",
    "* Converter as imagens para **tensor normalizado** (ex.: valores entre -1 e 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "        self.images = [\n",
    "            os.path.join(folder, f)\n",
    "            for f in os.listdir(folder)\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eac31f",
   "metadata": {},
   "source": [
    "### Carregamento\n",
    "\n",
    "Carregue os dados a partir do seu dataset de imagens e aplique os transforms necessários. Caso o dataset seja pequeno, recomenda-se o uso de data augmentation (como flips horizontais, jitter de cor ou pequenas rotações) para aumentar a diversidade das amostras e melhorar a estabilidade do treinamento adversarial. Em seguida, defina um batch size adequado e instancie um DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    # Caso tenha poucas imagens, adicione data augmentation aqui\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# train_dataset = ImageDataset(...)\n",
    "# train_loader = DataLoader(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab12706e",
   "metadata": {},
   "source": [
    "## Definição dos Modelos\n",
    "\n",
    "Para este exercício, deverão ser utilizadas DCGANs com distância de Wasserstein. Nesta seção, defina a arquitetura dos modelos Gerador e Crítico, implementando o treinamento adversarial baseado na métrica de Wasserstein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772e16d",
   "metadata": {},
   "source": [
    "### Gerador\n",
    "\n",
    "O Gerador seguirá a arquitetura típica de uma DCGAN, produzindo amostras sintéticas a partir de vetores de ruído, enquanto o Crítico avaliará a distância entre as distribuições reais e geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf517a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fde9ec0",
   "metadata": {},
   "source": [
    "### Crítico\n",
    "\n",
    "O Crítico (substituindo o discriminador tradicional) deve utilizar gradient clipping para garantir o cumprimento da restrição de Lipschitz, condição essencial para a estabilidade da função de custo de Wasserstein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4971768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d36832a0",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Com o **Gerador** e o **Crítico** definidos, e os dados devidamente carregados, inicie o treinamento.\n",
    "\n",
    "Durante o processo:\n",
    "\n",
    "* Atualize o **Crítico** várias vezes para cada atualização do **Gerador**, garantindo uma estimativa mais precisa da distância de Wasserstein.\n",
    "* Aplique **gradient clipping** nos parâmetros do Crítico após cada atualização, mantendo a restrição de **Lipschitz**.\n",
    "* Utilize **losses baseadas na métrica de Wasserstein**.\n",
    "\n",
    "Ao longo do treinamento, **visualize amostras geradas** a cada determinado número de épocas, observando a evolução da qualidade das imagens produzidas pelo Gerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff7078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71daf4b7",
   "metadata": {},
   "source": [
    "## Inferência\n",
    "\n",
    "Após o treinamento, utilize o **Gerador** para produzir novas imagens a partir de **vetores de ruído aleatório**.\n",
    "Cada vetor servirá como ponto de partida no espaço latente, sendo transformado pelo modelo em uma amostra sintética do domínio aprendido.\n",
    "\n",
    "Durante a inferência:\n",
    "\n",
    "* Gere múltiplas imagens e visualize os resultados.\n",
    "* Analise a **qualidade e diversidade** das amostras produzidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ae553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
