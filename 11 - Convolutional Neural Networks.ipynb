{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8abc14",
   "metadata": {},
   "source": [
    "# Redes Neurais Convolucionais\n",
    "\n",
    "Neste notebook, exploraremos os fundamentos das Redes Neurais Convolucionais (Convolutional Neural Networks, ou CNNs), uma classe de redes neurais profundas que se tornou dominante em diversas tarefas de visão computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce80657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b220f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7e849",
   "metadata": {},
   "source": [
    "### Preparação dos Dados e do Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4bc3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "validation_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "train_subset = Subset(training_data, range(5000))\n",
    "validation_subset = Subset(validation_data, range(1000))\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_subset, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_subset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c693fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, validation_dataloader, criterion, optimizer, epochs=10):\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = correct_predictions / total_samples\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in validation_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_samples += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = running_loss / total_samples\n",
    "        epoch_val_acc = correct_predictions / total_samples\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
    "              f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "def plot_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history['train_acc'])\n",
    "    ax1.plot(history['val_acc'])\n",
    "    ax1.set_title('Model accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(history['train_loss'])\n",
    "    ax2.plot(history['val_loss'])\n",
    "    ax2.set_title('Model loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3be5a4",
   "metadata": {},
   "source": [
    "### As Camadas de uma CNN\n",
    "\n",
    "Redes Neurais Convolucionais introduzem camadas especializadas que são projetadas para extrair características hierárquicas de dados com estrutura de grade, como imagens. As duas camadas mais fundamentais são a convolucional (`Conv2d`) e a de pooling (`MaxPool2d`).\n",
    "\n",
    "#### Convolução 2D (`Conv2d`)\n",
    "\n",
    "A camada convolucional é o principal bloco de construção de uma CNN. Sua função é aplicar um conjunto de filtros (ou kernels) à imagem de entrada. Cada filtro é uma pequena matriz de pesos que desliza sobre a imagem, computando o produto de ponto entre os pesos do filtro e a porção da imagem sob ele. Este processo gera um mapa de ativação (ou mapa de características) que indica a presença de uma característica específica (e.g., uma borda vertical, uma curva) em diferentes locais da imagem.\n",
    "\n",
    "Os principais parâmetros da camada `torch.nn.Conv2d` são:\n",
    "* `in_channels`: O número de canais da imagem de entrada (e.g., 1 para escala de cinza, 3 para RGB).\n",
    "* `out_channels`: O número de filtros a serem aplicados. Cada filtro produzirá um canal no mapa de características de saída.\n",
    "* `kernel_size`: As dimensões (altura x largura) do filtro.\n",
    "* `stride`: O passo com que o filtro se move pela imagem. Um `stride` de 1 significa que o filtro se move um pixel de cada vez.\n",
    "* `padding`: Adição de pixels (geralmente com valor zero) ao redor da imagem de entrada. Isso é útil para controlar a dimensão espacial da saída.\n",
    "\n",
    "A dimensão da saída de uma camada convolucional pode ser calculada pela seguinte fórmula:\n",
    "\n",
    "$$\n",
    "W_{out} = \\frac{W_{in} - K + 2P}{S} + 1\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "* $W_{in}$ é a largura da entrada.\n",
    "* $K$ é o tamanho do kernel.\n",
    "* $P$ é o padding.\n",
    "* $S$ é o stride.\n",
    "\n",
    "A mesma fórmula se aplica à altura ($H_{out}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec402f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = torch.randn(1, 1, 28, 28) # (N, C_in, H, W)\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "feature_map = conv_layer(sample_image)\n",
    "\n",
    "print(f\"Input image: {sample_image.shape}\")\n",
    "print(f\"Feature map: {feature_map.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1592d55",
   "metadata": {},
   "source": [
    "#### Pooling (`MaxPool2d`)\n",
    "\n",
    "A camada de pooling é comumente inserida entre camadas convolucionais sucessivas em uma arquitetura de CNN. Seu objetivo principal é reduzir progressivamente a dimensão espacial (altura e largura) da representação, o que diminui a quantidade de parâmetros e computação na rede. Isso também ajuda a tornar a representação mais robusta a pequenas translações na imagem de entrada (invariância à translação).\n",
    "\n",
    "A operação de Max Pooling, implementada por `torch.nn.MaxPool2d`, seleciona o valor máximo de uma vizinhança definida pelo `kernel_size` no mapa de características.\n",
    "\n",
    "Os principais parâmetros são:\n",
    "* `kernel_size`: O tamanho da janela sobre a qual a operação de max pooling é aplicada.\n",
    "* `stride`: O passo com que a janela se move. Frequentemente, o `stride` é igual ao `kernel_size` para evitar sobreposição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02561bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "pooled_output = pool_layer(feature_map)\n",
    "\n",
    "print(f\"Feature map: {feature_map.shape}\")\n",
    "print(f\"Output: {pooled_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd6b10",
   "metadata": {},
   "source": [
    "#### Convolução Transposta (`ConvTranspose2d`)\n",
    "\n",
    "Enquanto a convolução e o pooling são operações que tipicamente reduzem a dimensionalidade espacial (downsampling) dos mapas de características, há cenários em que o processo inverso (upsampling) é necessário. A camada `ConvTranspose2d`, frequentemente, embora de forma imprecisa, chamada de \"deconvolução\", serve a este propósito.\n",
    "\n",
    "Sua função é realizar um upsampling do mapa de características de entrada para uma resolução espacial maior. Em vez de mapear uma vizinhança de múltiplos valores de entrada para um único valor de saída (como na convolução padrão), a convolução transposta mapeia um único valor de entrada para uma vizinhança de múltiplos valores de saída. Ela realiza esta operação aprendendo um conjunto de filtros, similar à `Conv2d`, mas o cálculo é estruturado para expandir as dimensões de altura e largura.\n",
    "\n",
    "Esta camada é fundamental em arquiteturas como autoencoders (na porção do decodificador), redes generativas (GANs) e em tarefas de segmentação semântica, onde é preciso reconstruir uma imagem ou um mapa de segmentação na resolução original a partir de um mapa de características de baixa dimensão.\n",
    "\n",
    "A dimensão da saída de uma camada de convolução transposta pode ser calculada pela seguinte fórmula:\n",
    "\n",
    "$$\n",
    "W_{out} = (W_{in} - 1) \\times S - 2P + K + OP\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "* $W_{in}$ é a largura da entrada.\n",
    "* $S$ é o `stride`.\n",
    "* $P$ é o `padding`.\n",
    "* $K$ é o `kernel_size`.\n",
    "* $OP$ é o `output_padding`, um parâmetro que ajuda a resolver ambiguidades no cálculo do tamanho da saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_conv_layer = nn.ConvTranspose2d(\n",
    "    in_channels=16, \n",
    "    out_channels=8, \n",
    "    kernel_size=2, \n",
    "    stride=2\n",
    ")\n",
    "\n",
    "upsampled_output = transpose_conv_layer(pooled_output)\n",
    "\n",
    "print(f\"Feature map: {pooled_output.shape}\")\n",
    "print(f\"Transposed convolution: {upsampled_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343cd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[[\n",
    "    [0, 1],\n",
    "    [2, 3]]\n",
    "]])\n",
    "kernel = torch.tensor([[[\n",
    "    [0, 1],\n",
    "    [2, 3]\n",
    "]]])\n",
    "\n",
    "output_tensor = nn.functional.conv_transpose2d(input_tensor, kernel, stride=1, padding=0)\n",
    "\n",
    "print(f\"Input:\\n{input_tensor.squeeze()}\\n\")\n",
    "print(f\"Kernel:\\n{kernel.squeeze()}\\n\")\n",
    "print(f\"Output:\\n{output_tensor.squeeze()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ecb4af",
   "metadata": {},
   "source": [
    "### Construção de um Modelo CNN para Classificação\n",
    "\n",
    "Agora, vamos combinar as camadas `Conv2d` e `MaxPool2d`, junto com uma função de ativação não-linear como a ReLU (`nn.ReLU`) e camadas lineares (`nn.Linear`) ao final, para construir uma CNN completa para a tarefa de classificação do MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_block = nn.Sequential(\n",
    "            nn.Linear(32 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_block(x)\n",
    "        return logits\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050fb128",
   "metadata": {},
   "source": [
    "### Treinamento e Avaliação do Modelo\n",
    "\n",
    "Com o modelo definido, podemos agora instanciar a função de perda e o otimizador. Utilizaremos `CrossEntropyLoss` para a classificação multi-classe e o otimizador `Adam`. Em seguida, passaremos tudo para nossa função de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f7f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    validation_dataloader=validation_dataloader,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec364be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84864c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "filters = model.cnn[0].weight.detach().cpu()\n",
    "\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters_normalized = (filters - f_min) / (f_max - f_min)\n",
    "\n",
    "num_filters = filters_normalized.shape[0]\n",
    "cols = int(math.ceil(math.sqrt(num_filters)))\n",
    "rows = int(math.ceil(num_filters / cols))\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(8, 8))\n",
    "fig.suptitle('Filtros da Primeira Camada Convolucional', fontsize=16)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(num_filters):\n",
    "    filt = filters_normalized[i, 0, :, :]\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.imshow(filt, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f\"Filtro {i+1}\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e277d97",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc35ba",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "Altere o dataset e o modelo para verificar se o dígito é ímpar ou par. A saída deve contar apenas um neurônio com função de ativação sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c420262",
   "metadata": {},
   "source": [
    "### Exercício 2\n",
    "\n",
    "Faça um modelo que receba como entrada um vetor de formato `(N, latent_dim)` e tenha como saída um tensor representando uma imagem com formato `(N, 3, 100, 100)`, onde `N` é o batch size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
