{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d962c0",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "Neste notebook, exploraremos a teoria e a implementação de Redes Adversárias Generativas (GANs) aplicadas a um conjunto de dados bidimensional. As GANs são uma classe de modelos de aprendizado de máquina que consiste em duas redes neurais que competem entre si em um jogo de soma zero. Utilizaremos um dataset sintético para visualizar o processo de aprendizagem do gerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0329d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333fe80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7fac3a",
   "metadata": {},
   "source": [
    "## Moons Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09811874",
   "metadata": {},
   "source": [
    "### Preparando Dados\n",
    "\n",
    "Para este estudo, utilizaremos o dataset `make_moons` da biblioteca `scikit-learn`. Este dataset é ideal para visualização, pois gera duas \"luas\" entrelaçadas em um espaço bidimensional. Ele nos permite observar diretamente como o gerador aprende a mapear uma distribuição de ruído para a distribuição complexa dos dados reais.\n",
    "\n",
    "Vamos gerar os pontos, convertê-los para tensores do PyTorch e criar um `DataLoader` para iterar sobre os dados em lotes (`batches`) durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc73d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "noise = 0.05\n",
    "\n",
    "X, y = make_moons(n_samples=n_samples, noise=noise, random_state=42)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54630d",
   "metadata": {},
   "source": [
    "### Redes Adversárias Generativas (GANs)\n",
    "\n",
    "As GANs são compostas por duas redes neurais: o Gerador ($G$) e o Discriminador ($D$). Ambas são treinadas simultaneamente em um processo competitivo.\n",
    "\n",
    "#### O Gerador e o Discriminador\n",
    "\n",
    "* **Gerador ($G$)**: A sua função é aprender a criar dados sintéticos que sejam indistinguíveis dos dados reais. Ele recebe um vetor de ruído aleatório (vetor latente $z$), tipicamente amostrado de uma distribuição normal, e produz uma amostra de dados, $G(z)$, que se assemelha à distribuição dos dados de treinamento.\n",
    "\n",
    "* **Discriminador ($D$)**: É uma rede classificadora binária que tenta distinguir entre amostras de dados reais e amostras falsas geradas pelo Gerador. Ele recebe uma amostra de dados ($x$) e retorna uma probabilidade, $D(x)$, que representa a chance de $x$ ser uma amostra real.\n",
    "\n",
    "#### O Processo de Treinamento Adversário\n",
    "\n",
    "O treinamento ocorre como um jogo. O Discriminador é treinado para maximizar sua acurácia ao classificar corretamente amostras reais e falsas. Simultaneamente, o Gerador é treinado para \"enganar\" o Discriminador, ou seja, para gerar amostras que o Discriminador classifique como reais.\n",
    "\n",
    "#### A Função de Perda Minimax\n",
    "\n",
    "O objetivo do treinamento da GAN é encontrar um equilíbrio de Nash no jogo entre o Gerador e o Discriminador. A função de valor $V(D, G)$ que o Discriminador tenta maximizar e o Gerador tenta minimizar é dada por:\n",
    "\n",
    "$$\n",
    "\\min_{G} \\max_{D} V(D, G) = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_{z}(z)}[\\log(1 - D(G(z)))]\n",
    "$$\n",
    "\n",
    "Nesta equação:\n",
    "* $\\mathbb{E}_{x \\sim p_{\\text{data}}(x)}$ é o valor esperado sobre as amostras reais $x$ da distribuição de dados $p_{\\text{data}}$.\n",
    "* $\\mathbb{E}_{z \\sim p_{z}(z)}$ é o valor esperado sobre os vetores de ruído $z$ da distribuição de ruído $p_{z}$.\n",
    "* $D(x)$ é a probabilidade de que a amostra real $x$ seja real. O Discriminador quer maximizar este termo.\n",
    "* $D(G(z))$ é a estimativa do Discriminador da probabilidade de que uma amostra falsa seja real. O Gerador quer maximizar este valor, enquanto o Discriminador quer minimizá-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = torch.from_numpy(X).float()\n",
    "dataset = TensorDataset(real_data)\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0c0db",
   "metadata": {},
   "source": [
    "### Implementação da GAN\n",
    "\n",
    "Agora, implementaremos as redes Geradora e Discriminadora. Como nossos dados são bidimensionais, podemos usar arquiteturas de Perceptron de Múltiplas Camadas (MLP) relativamente simples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d809a",
   "metadata": {},
   "source": [
    "#### Gerador\n",
    "\n",
    "O Gerador receberá um vetor de ruído e o transformará em um ponto 2D. Utilizaremos camadas lineares e funções de ativação `ReLU`. A camada de saída não terá função de ativação, pois os dados não estão em um intervalo específico como `[-1, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(32, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d77d76f",
   "metadata": {},
   "source": [
    "#### Discriminador\n",
    "\n",
    "O Discriminador receberá um ponto 2D e produzirá um único valor escalar indicando a probabilidade daquele ponto ser real. A camada de saída utilizará a função de ativação `Sigmoid` para mapear a saída para o intervalo `[0, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd315d",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo\n",
    "\n",
    "O treinamento da GAN será realizado em um loop. Em cada época, iremos treinar o Discriminador e o Gerador de forma alternada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de99cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "output_dim = 2\n",
    "\n",
    "G = Generator(latent_dim, output_dim).to(device)\n",
    "D = Discriminator(output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddaac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "\n",
    "# Função de perda\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Otimizadores\n",
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36136586",
   "metadata": {},
   "source": [
    "#### O Loop de Treinamento\n",
    "\n",
    "O loop de treinamento segue os passos canônicos da GAN:\n",
    "\n",
    "1.  **Treinamento do Discriminador**: Atualizamos os pesos de $D$ para que ele maximize a probabilidade de classificar corretamente amostras reais (rótulo 1) e falsas (rótulo 0).\n",
    "2.  **Treinamento do Gerador**: Atualizamos os pesos de $G$ para que ele maximize a probabilidade de $D$ classificar suas amostras geradas como reais (rótulo 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "plot_interval = 100\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (real_samples,) in enumerate(train_dataloader):\n",
    "        real_samples = real_samples.to(device)\n",
    "        batch_size = real_samples.size(0)\n",
    "        valid_labels = torch.ones(batch_size, 1, device=device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "\n",
    "        # --- Treinamento do Discriminador ---\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        noise_vector = torch.randn(batch_size, latent_dim, device=device)\n",
    "        generated_samples = G(noise_vector)\n",
    "        \n",
    "        real_loss = adversarial_loss(D(real_samples), valid_labels)\n",
    "        fake_loss = adversarial_loss(D(generated_samples.detach()), fake_labels)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --- Treinamento do Gerador ---\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        noise_vector = torch.randn(batch_size, latent_dim, device=device)\n",
    "        generated_samples = G(noise_vector)\n",
    "        \n",
    "        g_loss = adversarial_loss(D(generated_samples), valid_labels)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "    g_losses.append(g_loss.item())\n",
    "    d_losses.append(d_loss.item())\n",
    "    \n",
    "    if epoch % plot_interval == 0 or epoch in {1, 2, 5, 10}:\n",
    "        print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            z_plot = torch.randn(n_samples, latent_dim, device=device)\n",
    "            generated_for_plot = G(z_plot).cpu().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "        plt.scatter(generated_for_plot[:, 0], generated_for_plot[:, 1], alpha=0.7, c='red', s=10)\n",
    "        plt.title(f\"Epoch {epoch}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62724195",
   "metadata": {},
   "source": [
    "## Aplicação: MNIST\n",
    "\n",
    "Após visualizar o comportamento da GAN em um ambiente bidimensional controlado, vamos agora aplicar o mesmo conceito a um problema mais complexo e prático: a geração de imagens de dígitos manuscritos a partir do dataset MNIST. A arquitetura das redes Geradora e Discriminadora continuará sendo baseada em Perceptrons de Múltiplas Camadas (MLPs), mas adaptada para lidar com as dimensões das imagens (28x28 pixels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb7bed",
   "metadata": {},
   "source": [
    "### Carregamento e Preparação dos Dados\n",
    "\n",
    "Primeiramente, carregamos o dataset MNIST utilizando o `torchvision`. As imagens serão normalizadas para o intervalo `[-1, 1]`. Esta normalização é importante para que os valores dos pixels correspondam ao intervalo da função de ativação da camada de saída do Gerador, que será a Tangente Hiperbólica (`tanh`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ab8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5], std=[0.5])  # Normaliza os tensores para o intervalo [-1, 1]\n",
    "])\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "validation_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_subset = Subset(training_data, range(20000))\n",
    "validation_subset = Subset(validation_data, range(5000))\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b192070",
   "metadata": {},
   "source": [
    "### Definição dos Modelos\n",
    "\n",
    "As arquiteturas do Gerador e do Discriminador serão MLPs. O Gerador receberá um vetor do espaço latente e sua tarefa será gerar uma imagem achatada de 784 pixels (28x28). O Discriminador, por sua vez, receberá uma imagem achatada e deverá produzir um valor de probabilidade indicando se a imagem é real ou falsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super().__init__()\n",
    "        self.img_shape = img_shape\n",
    "        output_dim = int(np.prod(img_shape))\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(1024, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img.view(z.size(0), *self.img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(img.size(0), -1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc7413d",
   "metadata": {},
   "source": [
    "### Treinamento da GAN no MNIST\n",
    "\n",
    "O processo de treinamento segue a mesma lógica adversária. Definimos os hiperparâmetros, instanciamos os modelos e otimizadores, e iniciamos o loop de treinamento, alternando entre a otimização do Discriminador e do Gerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "img_shape = (1, 28, 28)\n",
    "\n",
    "G = Generator(latent_dim, img_shape).to(device)\n",
    "D = Discriminator(img_shape).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ec559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de perda\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Otimizadores\n",
    "lr = 0.0002\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a87769",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "plot_interval = 5\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    G.train(); D.train()\n",
    "    g_running, d_running = 0, 0\n",
    "\n",
    "    for imgs, _ in train_dataloader:\n",
    "        valid = torch.ones(imgs.size(0), 1, device=device)\n",
    "        fake = torch.zeros(imgs.size(0), 1, device=device)\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        # --- Treina D ---\n",
    "        D_optimizer.zero_grad()\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device=device)\n",
    "        gen_imgs = G(z).detach()\n",
    "        real_loss = criterion(D(real_imgs), valid)\n",
    "        fake_loss = criterion(D(gen_imgs), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # --- Treina G ---\n",
    "        G_optimizer.zero_grad()\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device=device)\n",
    "        gen_imgs = G(z)\n",
    "        g_loss = criterion(D(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        d_running += d_loss.item()\n",
    "        g_running += g_loss.item()\n",
    "\n",
    "    g_losses.append(g_running / len(train_dataloader))\n",
    "    d_losses.append(d_running / len(train_dataloader))\n",
    "\n",
    "    if epoch % plot_interval == 0:\n",
    "        print(f\"[{epoch}/{n_epochs}] D: {d_losses[-1]:.4f} | G: {g_losses[-1]:.4f}\")\n",
    "        \n",
    "        n_images = 8\n",
    "        z = torch.randn(n_images, latent_dim, device=device)\n",
    "        generated_imgs = G(z).detach().cpu()\n",
    "        fig, axs = plt.subplots(2, 4, figsize=(8, 4))\n",
    "        for i in range(n_images):\n",
    "            row = i // 4\n",
    "            col = i % 4\n",
    "            axs[row, col].imshow(generated_imgs[i].squeeze(), cmap=\"gray\")\n",
    "            axs[row, col].axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c391e441",
   "metadata": {},
   "source": [
    "### Análise dos Resultados e Geração de Amostras\n",
    "\n",
    "Após o treinamento, podemos analisar as curvas de perda. Idealmente, a perda do Discriminador ($D_{loss}$) deve permanecer em torno de 0.5, indicando que ele não consegue distinguir facilmente entre o real e o falso. A perda do Gerador ($G_{loss}$) deve diminuir, indicando que está melhorando em enganar o Discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c33e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(g_losses, label=\"G\")\n",
    "plt.plot(d_losses, label=\"D\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6eeba",
   "metadata": {},
   "source": [
    "#### Geração de Novos Dígitos\n",
    "\n",
    "Agora, vamos usar o Gerador treinado para criar novos dígitos manuscritos. Para isso, basta passar um vetor de ruído aleatório pela rede do Gerador e visualizar a imagem resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 16\n",
    "z = torch.randn(n_images, latent_dim, device=device)\n",
    "generated_imgs = G(z).detach().cpu()\n",
    "print(generated_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i in range(n_images):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axs[row, col].imshow(generated_imgs[i].squeeze(), cmap=\"gray\")\n",
    "    axs[row, col].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd4ab4",
   "metadata": {},
   "source": [
    "### Interpolação no Espaço Latente\n",
    "\n",
    "Uma propriedade interessante das GANs é a capacidade de interpolar no espaço latente. O espaço latente é o espaço vetorial de onde os vetores de ruído $z$ são amostrados. Ao mover-se suavemente de um ponto a outro neste espaço, podemos gerar uma transição suave entre as imagens correspondentes.\n",
    "\n",
    "Para demonstrar isso, vamos escolher dois vetores de ruído aleatórios, $z_1$ e $z_2$. Em seguida, criaremos uma sequência de vetores intermediários através de uma interpolação linear:\n",
    "\n",
    "$$\n",
    "z_{\\text{interp}} = \\alpha \\cdot z_1 + (1 - \\alpha) \\cdot z_2\n",
    "$$\n",
    "\n",
    "onde $\\alpha$ varia de 0 a 1. Passando cada $z_{\\text{interp}}$ pelo Gerador, obteremos uma sequência de imagens que mostra uma transição de um dígito para outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar dois pontos aleatórios no espaço latente\n",
    "z1 = torch.randn(1, latent_dim, device=device)\n",
    "z2 = torch.randn(1, latent_dim, device=device)\n",
    "\n",
    "# Número de passos para a interpolação\n",
    "n_steps = 10\n",
    "alpha_values = np.linspace(0, 1, n_steps)\n",
    "\n",
    "# Gerar imagens interpoladas\n",
    "interpolated_imgs = []\n",
    "for alpha in alpha_values:\n",
    "    # Interpolação linear\n",
    "    z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "    \n",
    "    # Gerar imagem\n",
    "    img = G(z_interp).detach().cpu()\n",
    "    interpolated_imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8010c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, n_steps, figsize=(15, 3))\n",
    "for i in range(n_steps):\n",
    "    axs[i].imshow(interpolated_imgs[i].squeeze(), cmap=\"gray\")\n",
    "    axs[i].axis(\"off\")\n",
    "    axs[i].set_title(f\"α={alpha_values[i]:.2f}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
