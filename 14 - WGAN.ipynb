{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943c96d5",
   "metadata": {},
   "source": [
    "# Wasserstein Generative Adversarial Networks (WGAN)\n",
    "\n",
    "Neste notebook, vamos explorar a Wasserstein GAN (WGAN), uma evolução significativa das Redes Adversariais Generativas que visa resolver alguns dos problemas mais persistentes do treinamento de GANs tradicionais, como a instabilidade e o colapso de modo. A principal inovação da WGAN é a substituição da divergência Jensen-Shannon (JS), implícita na função de custo da GAN original, pela Distância de Wasserstein-1, também conhecida como \"Earth Mover's Distance\". Isso resulta em uma função de perda que se correlaciona melhor com a qualidade das imagens geradas e proporciona gradientes mais estáveis, tornando o treinamento mais robusto. Construiremos nossa WGAN sobre a arquitetura convolucional da DCGAN, modificando a função de perda, a arquitetura do \"Crítico\" e o algoritmo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc757d75",
   "metadata": {},
   "source": [
    "### A Distância de Wasserstein\n",
    "\n",
    "O treinamento de GANs tradicionais é notoriamente instável. Isso se deve em grande parte à função de perda baseada na divergência JS, que pode saturar facilmente, resultando em gradientes que desaparecem (*vanishing gradients*). Quando o Discriminador se torna muito bom, o gradiente para o Gerador vai a zero, e o aprendizado para.\n",
    "\n",
    "A WGAN propõe o uso da Distância de Wasserstein-1 ($W(P_r, P_g)$), que mede a \"distância\" entre a distribuição de dados reais ($P_r$) e a distribuição de dados gerados ($P_g$). Intuitivamente, pode ser vista como o \"custo\" mínimo para transformar uma distribuição na outra, como o custo de mover uma pilha de terra para que ela assuma a forma de outra.\n",
    "\n",
    "$$\n",
    "W(P_r, P_g) = \\inf_{\\gamma \\in \\Pi(P_r, P_g)} \\mathbb{E}_{(x, y) \\sim \\gamma} [\\|x - y\\|]\n",
    "$$\n",
    "\n",
    "Esta formulação é intratável. No entanto, a dualidade de Kantorovich-Rubinstein nos oferece uma forma alternativa e mais prática:\n",
    "\n",
    "$$\n",
    "W(P_r, P_g) = \\sup_{\\|f\\|_L \\le 1} \\mathbb{E}_{x \\sim P_r}[f(x)] - \\mathbb{E}_{x \\sim P_g}[f(x)]\n",
    "$$\n",
    "\n",
    "Aqui, o supremo é obtido sobre todas as funções 1-Lipschitz $f$. Uma função é K-Lipschitz se $|f(x_1) - f(x_2)| \\le K|x_1 - x_2|$. Na prática, a WGAN parametriza a função $f$ com uma rede neural, que chamamos de **Crítico** (em vez de Discriminador). O trabalho do Crítico é encontrar uma função $f$ que maximize a diferença acima. O trabalho do Gerador é produzir amostras que minimizem essa mesma diferença.\n",
    "\n",
    "Para forçar a restrição de Lipschitz, o artigo original da WGAN propõe uma solução simples: o **weight clipping**. Após cada atualização de gradiente, os pesos do Crítico são \"clipados\" para um pequeno intervalo, como $[-0.01, 0.01]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a79d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3fff6",
   "metadata": {},
   "source": [
    "### Preparação dos Dados (MNIST)\n",
    "\n",
    "Para treinar nossa DCGAN, utilizaremos o dataset MNIST. As imagens serão redimensionadas para 32x32 para facilitar uma arquitetura com múltiplas camadas de convolução transposta que dobram a dimensão espacial. Além disso, normalizaremos os pixels das imagens para o intervalo `[-1, 1]`, que corresponde à faixa da função de ativação `Tanh` na camada de saída do nosso Gerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24fab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]) # Normaliza para [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Número de batches de treino: {len(train_dataloader)}\")\n",
    "print(f\"Número de batches de teste: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79f913",
   "metadata": {},
   "source": [
    "### O Gerador\n",
    "\n",
    "A arquitetura do Gerador pode ser mantida exatamente a mesma da DCGAN. Sua função ainda é mapear um vetor do espaço latente para o espaço de imagens. A inovação da WGAN não está na arquitetura dos modelos, mas sim na forma como eles são treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a426b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_channels, features_g):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, features_g * 8, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 8, features_g * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(features_g * 2, img_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cfe728",
   "metadata": {},
   "source": [
    "### O Crítico (Critic)\n",
    "\n",
    "A arquitetura do Discriminador da DCGAN é reaproveitada, mas com uma mudança: a camada final de ativação `Sigmoid` é **removida**. O modelo, que agora chamamos de Crítico, não deve produzir uma probabilidade, mas sim um score (um número real) para cada imagem. Esse score é usado para aproximar a Distância de Wasserstein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, img_channels, features_d):\n",
    "        super(Critic, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, features_d, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d, features_d * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features_d * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(features_d * 2, features_d * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features_d * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # A camada final não tem Sigmoid, produz um score\n",
    "            nn.Conv2d(features_d * 4, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ecc3ad",
   "metadata": {},
   "source": [
    "### Inicialização e Instanciação dos Modelos\n",
    "\n",
    "Instanciamos os modelos e aplicamos a mesma inicialização de pesos da DCGAN. A mudança principal aqui é o otimizador: o artigo da WGAN recomenda o uso do `RMSprop` em vez de Adam com momento, pois observaram maior estabilidade. Não precisamos mais de uma função de perda como `BCELoss`, pois o custo será calculado diretamente a partir dos scores do Crítico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c2cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "features_g = 16\n",
    "latent_dim = 100\n",
    "img_channels = 1\n",
    "\n",
    "# Instanciação dos modelos\n",
    "generator = Generator(latent_dim, img_channels, features_g=64).to(device)\n",
    "generator.apply(weights_init)\n",
    "\n",
    "critic = Critic(img_channels, features_d=64).to(device)\n",
    "critic.apply(weights_init)\n",
    "\n",
    "print(\"Generator Architecture:\\n\", generator)\n",
    "print(\"\\nCritic Architecture:\\n\", critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00005\n",
    "\n",
    "# Otimizadores (RMSprop é recomendado para WGAN)\n",
    "optimizer_g = RMSprop(generator.parameters(), lr=lr)\n",
    "optimizer_c = RMSprop(critic.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92bd8a9",
   "metadata": {},
   "source": [
    "### Loop de Treinamento\n",
    "\n",
    "O loop de treinamento da WGAN é diferente do de uma GAN padrão. Para cada atualização do Gerador, o Crítico é atualizado múltiplas vezes (`n_critic`). Isso é feito para garantir que o Crítico se aproxime bem da função 1-Lipschitz ótima.\n",
    "\n",
    "1.  **Treinamento do Crítico**:\n",
    "    * A perda do Crítico visa maximizar $f(x) - f(G(z))$. Como otimizadores fazem minimização, minimizamos o negativo: $-(f(x) - f(G(z)))$, que é $f(G(z)) - f(x)$.\n",
    "    * Após a atualização dos pesos, aplicamos o **weight clipping** para forçar a restrição de Lipschitz.\n",
    "\n",
    "2.  **Treinamento do Gerador**:\n",
    "    * A perda do Gerador visa minimizar a Distância de Wasserstein, o que corresponde a maximizar o score que o Crítico dá para suas imagens falsas, $f(G(z))$. Portanto, minimizamos $-f(G(z))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "n_critic = 5 # Número de vezes que o crítico é treinado por iteração do gerador\n",
    "clip_value = 0.01 # Valor para o weight clipping\n",
    "plot_interval = 1\n",
    "\n",
    "g_losses = []\n",
    "c_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    generator.train()\n",
    "    critic.train()\n",
    "    \n",
    "    g_running_loss = 0.0\n",
    "    c_running_loss = 0.0\n",
    "\n",
    "    for i, (real_imgs, _) in enumerate(train_dataloader):\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        b_size = real_imgs.size(0)\n",
    "\n",
    "        # --- Treinamento do Crítico (n_critic iterações) ---\n",
    "        for _ in range(n_critic):\n",
    "            optimizer_c.zero_grad()\n",
    "            \n",
    "            noise = torch.randn(b_size, latent_dim, 1, 1, device=device)\n",
    "            fake_imgs = generator(noise).detach()\n",
    "            \n",
    "            critic_real = critic(real_imgs).view(-1).mean()\n",
    "            critic_fake = critic(fake_imgs).view(-1).mean()\n",
    "            \n",
    "            # A perda do crítico é -(score_real - score_fake)\n",
    "            loss_c = -(critic_real - critic_fake)\n",
    "            loss_c.backward()\n",
    "            optimizer_c.step()\n",
    "\n",
    "            # Clip weights of critic\n",
    "            for p in critic.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "        \n",
    "        c_running_loss += loss_c.item()\n",
    "        \n",
    "        # --- Treinamento do Gerador ---\n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        noise = torch.randn(b_size, latent_dim, 1, 1, device=device)\n",
    "        gen_imgs = generator(noise)\n",
    "        output = critic(gen_imgs).view(-1).mean()\n",
    "        \n",
    "        # A perda do gerador é -score_fake\n",
    "        loss_g = -output\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        g_running_loss += loss_g.item()\n",
    "\n",
    "    g_epoch_loss = g_running_loss / len(train_dataloader)\n",
    "    c_epoch_loss = c_running_loss / len(train_dataloader)\n",
    "    \n",
    "    g_losses.append(g_epoch_loss)\n",
    "    c_losses.append(c_epoch_loss)\n",
    "\n",
    "    if epoch % plot_interval == 0 or epoch == num_epochs - 1:\n",
    "        print(f\"[{epoch}/{num_epochs-1}] Loss C: {c_epoch_loss:.4f} | Loss G: {g_epoch_loss:.4f}\")\n",
    "        \n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            n_images = 8\n",
    "            sample_noise = torch.randn(n_images, latent_dim, 1, 1, device=device)\n",
    "            generated_imgs = generator(sample_noise).detach().cpu()\n",
    "\n",
    "            fig, axs = plt.subplots(2, 4, figsize=(8, 4))\n",
    "            fig.suptitle(f'Imagens Geradas na Época {epoch}', fontsize=16)\n",
    "            for i in range(n_images):\n",
    "                row = i // 4\n",
    "                col = i % 4\n",
    "                axs[row, col].imshow(generated_imgs[i].squeeze(), cmap=\"gray\", vmin=-1, vmax=1)\n",
    "                axs[row, col].axis(\"off\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d3335",
   "metadata": {},
   "source": [
    "### Análise dos Resultados\n",
    "\n",
    "Uma das vantagens da WGAN é que a perda do Crítico ($f(G(z)) - f(x)$) se aproxima da Distância de Wasserstein, que tende a se correlacionar com a qualidade das imagens geradas. Ao contrário da perda de uma GAN tradicional, aqui, uma perda do Crítico menor (mais negativa) indica que a distância entre as distribuições real e gerada é maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6122d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o gráfico de perdas\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Critic and Generator Loss During Training\")\n",
    "plt.plot(c_losses, label=\"Critic Loss\")\n",
    "plt.plot(g_losses, label=\"Generator Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
