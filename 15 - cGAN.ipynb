{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd06eb0e",
   "metadata": {},
   "source": [
    "# Redes Adversárias Generativas Condicionais (cGANs)\n",
    "\n",
    "Neste notebook, exploraremos uma extensão poderosa das Redes Adversárias Generativas (GANs) padrão: as GANs Condicionais, ou cGANs. Enquanto uma GAN tradicional aprende a mapear um vetor de ruído latente $z$ para uma amostra de dados (por exemplo, uma imagem), sem controle sobre qual amostra é gerada, uma cGAN introduz informação adicional $y$ (como um rótulo de classe) tanto no Gerador quanto no Discriminador. Isso nos permite controlar explicitamente as características das amostras geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2a87a",
   "metadata": {},
   "source": [
    "## Preparação dos Dados\n",
    "\n",
    "Agora, carregamos o dataset MNIST. Para agilizar o processo de treinamento, utilizaremos um subconjunto reduzido. O `ToTensor()` transforma as imagens do formato PIL para tensores e normaliza os pixels para o intervalo $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57037228",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "img_size = 28 * 28\n",
    "num_classes = 10\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]) # Normaliza para [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "batch_size = 128\n",
    "img_size = train_dataset[0][0].shape[1] * train_dataset[0][0].shape[2]\n",
    "num_classes = len(set(train_dataset.targets.numpy()))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Número de batches de treino: {len(train_dataloader)}\")\n",
    "print(f\"Número de batches de teste: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e9b8af",
   "metadata": {},
   "source": [
    "## Teoria das cGANs\n",
    "\n",
    "Uma GAN padrão consiste em duas redes neurais, o Gerador ($G$) e o Discriminador ($D$), que competem em um jogo de soma zero. O Gerador tenta criar dados sintéticos que se assemelham aos dados reais, enquanto o Discriminador tenta distinguir entre amostras reais e falsas. A função de valor (objetivo) para este jogo é:\n",
    "\n",
    "$$\n",
    "\\min_{G} \\max_{D} V(D, G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_{z}(z)}[\\log(1 - D(G(z)))]\n",
    "$$\n",
    "\n",
    "Nas cGANs, estendemos este framework ao condicionar ambas as redes a uma informação extra $y$. Essa informação pode ser um rótulo de classe, parte de uma imagem ou dados de outra modalidade. O vetor de ruído latente $z$ e a condição $y$ são combinados para alimentar o Gerador. O Discriminador, por sua vez, recebe como entrada tanto a imagem (real ou falsa) quanto a condição $y$.\n",
    "\n",
    "A nova função objetivo se torna:\n",
    "\n",
    "$$\n",
    "\\min_{G} \\max_{D} V(D, G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x|y)] + \\mathbb{E}_{z \\sim p_{z}(z)}[\\log(1 - D(G(z|y)))]\n",
    "$$\n",
    "\n",
    "Dessa forma, o Gerador aprende a gerar amostras que não apenas parecem reais, mas que também correspondem à condição $y$ fornecida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54db7b",
   "metadata": {},
   "source": [
    "## Implementação dos Modelos\n",
    "\n",
    "Para implementar a condicionalidade, usaremos uma camada de `Embedding` para transformar os rótulos de classe (números inteiros de 0 a 9) em vetores densos. Esses vetores serão concatenados tanto com o ruído latente na entrada do Gerador quanto com a imagem na entrada do Discriminador.\n",
    "\n",
    "### Gerador\n",
    "\n",
    "O Gerador receberá um vetor de ruído latente e um rótulo de classe. Ele combinará essas duas informações e produzirá uma imagem com as dimensões do MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes, img_size):\n",
    "        super().__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim + num_classes, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, img_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        gen_input = torch.cat((noise, label_embedding), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fd9d5",
   "metadata": {},
   "source": [
    "### Discriminador\n",
    "\n",
    "O Discriminador receberá uma imagem e um rótulo de classe. Seu objetivo é determinar se a imagem é uma amostra real correspondente àquele rótulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes, img_size):\n",
    "        super().__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_classes + img_size, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        label_embedding = self.label_embedding(labels)\n",
    "        d_in = torch.cat((img_flat, label_embedding), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "n_epochs = 50\n",
    "\n",
    "generator = Generator(latent_dim, num_classes, img_size).to(device)\n",
    "discriminator = Discriminator(num_classes, img_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de custo\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Otimizadores\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae103347",
   "metadata": {},
   "source": [
    "## Loop de Treinamento\n",
    "\n",
    "O treinamento de uma GAN envolve um processo de duas etapas dentro de cada época:\n",
    "\n",
    "1.  **Treinamento do Discriminador**:\n",
    "    * Apresentamos ao Discriminador um lote de imagens reais com seus rótulos correspondentes e calculamos sua perda. O objetivo é que ele classifique essas imagens como `1` (real).\n",
    "    * Geramos um lote de imagens falsas usando o Gerador, com rótulos aleatórios. Apresentamos essas imagens falsas ao Discriminador e calculamos sua perda. O objetivo é que ele classifique essas como `0` (falso).\n",
    "    * A perda total do Discriminador é a soma das perdas nas amostras reais e falsas. Atualizamos os pesos do Discriminador através de retropropagação.\n",
    "\n",
    "2.  **Treinamento do Gerador**:\n",
    "    * Geramos um novo lote de imagens falsas.\n",
    "    * Passamos essas imagens pelo Discriminador.\n",
    "    * Calculamos a perda do Gerador com base na saída do Discriminador, mas desta vez, o objetivo do Gerador é \"enganar\" o Discriminador. Portanto, a perda é calculada comparando a saída do Discriminador com rótulos de `1` (real).\n",
    "    * Atualizamos os pesos do Gerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "plot_interval = 1\n",
    "g_losses, d_losses = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    g_loss, d_loss = 0, 0\n",
    "\n",
    "    for imgs, labels in train_dataloader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        N = imgs.size(0)\n",
    "\n",
    "        valid = torch.ones(N, 1, device=device)\n",
    "        fake = torch.zeros(N, 1, device=device)\n",
    "\n",
    "        # --- Discriminador ---\n",
    "        optimizer_D.zero_grad()\n",
    "        real_pred = discriminator(imgs, labels)\n",
    "        loss_d_real = adversarial_loss(real_pred, valid)\n",
    "\n",
    "        z = torch.randn(N, latent_dim, device=device)\n",
    "        gen_labels = torch.randint(0, num_classes, (N,), device=device)\n",
    "        fake_imgs = generator(z, gen_labels).detach()\n",
    "\n",
    "        fake_pred = discriminator(fake_imgs, gen_labels)\n",
    "        loss_d_fake = adversarial_loss(fake_pred, fake)\n",
    "\n",
    "        loss_d = 0.5 * (loss_d_real + loss_d_fake)\n",
    "        loss_d.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --- Gerador ---\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(N, latent_dim, device=device)\n",
    "        gen_labels = torch.randint(0, num_classes, (N,), device=device)\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        loss_g = adversarial_loss(validity, valid)\n",
    "        loss_g.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        d_loss += loss_d.item()\n",
    "        g_loss += loss_g.item()\n",
    "\n",
    "    g_losses.append(g_loss / len(train_dataloader))\n",
    "    d_losses.append(d_loss / len(train_dataloader))\n",
    "\n",
    "    if epoch % plot_interval == 0 or epoch == num_epochs - 1:\n",
    "        print(f\"[{epoch}/{num_epochs-1}] D: {d_losses[-1]:.4f} | G: {g_losses[-1]:.4f}\")\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(num_classes, latent_dim, device=device)\n",
    "            sample_labels = torch.arange(0, num_classes, device=device) % num_classes\n",
    "            gen_imgs = generator(z, sample_labels).cpu()\n",
    "\n",
    "        fig, axs = plt.subplots(2, num_classes // 2, figsize=(num_classes, 4))\n",
    "        for i, ax in enumerate(axs.flat):\n",
    "            ax.imshow(gen_imgs[i].squeeze(), cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "        plt.suptitle(f\"Época {epoch}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299facde",
   "metadata": {},
   "source": [
    "### Análise dos Resultados\n",
    "\n",
    "Após o treinamento, podemos analisar os resultados de duas formas principais: visualizando a curva de perda do Gerador e do Discriminador e observando as imagens geradas ao longo do tempo. Idealmente, as perdas de $D$ e $G$ devem convergir para um estado de equilíbrio, embora na prática elas flutuem bastante. A análise mais importante é a qualidade visual das imagens geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o gráfico de perdas\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(g_losses, label=\"G\")\n",
    "plt.plot(d_losses, label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f80e65",
   "metadata": {},
   "source": [
    "## Análise dos Resultados\n",
    "\n",
    "Durante o treinamento, é esperado que as perdas do Gerador e do Discriminador flutuem. Idealmente, elas devem atingir um equilíbrio, onde nenhuma das redes supera completamente a outra. Se a perda do Discriminador cair para perto de zero, significa que ele está identificando as imagens falsas com muita facilidade, e o Gerador não está aprendendo. Se a perda do Gerador cair muito, o Discriminador pode não estar aprendendo a distinguir as amostras. O equilíbrio de Nash é o ponto ótimo, mas é notoriamente difícil de alcançar na prática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9022afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_digit(digit, num_samples=10):\n",
    "    # Preparar ruído e rótulos\n",
    "    z = torch.randn(num_samples, latent_dim, device=device)\n",
    "    labels = torch.full((num_samples,), digit, dtype=torch.long, device=device)\n",
    "    \n",
    "    # Gerar imagens\n",
    "    generator.eval() # Modo de avaliação\n",
    "    with torch.no_grad():\n",
    "        generated_imgs = generator(z, labels)\n",
    "    generator.train() # Voltar para o modo de treino\n",
    "    \n",
    "    # Desnormalizar e exibir\n",
    "    generated_imgs = 0.5 * generated_imgs + 0.5 # Desfaz a normalização [-1, 1] para [0, 1]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(15, 2))\n",
    "    fig.suptitle(f'Dígito {digit}', fontsize=16)\n",
    "    for i in range(num_samples):\n",
    "        axs[i].imshow(generated_imgs[i, 0].cpu().numpy(), cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Gerar exemplos para cada dígito\n",
    "for i in range(10):\n",
    "    generate_digit(i, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81e593",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8a827",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "Treine uma cGAN em que as labels sejam 1 ou 0 para números ímpares ou pares no MNIST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
